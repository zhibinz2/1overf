{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.0.2.\n"
     ]
    }
   ],
   "source": [
    "from hdf5storage import loadmat, savemat \n",
    "import numpy as np \n",
    "\n",
    "from scipy import signal \n",
    "from scipy.fftpack import fft\n",
    "\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__)) \n",
    "# make sure it is newer version, works in version 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load abs_zscore_all\n",
    "outdict=loadmat('../Pcorr_single_model/abs_zscore_all.mat')\n",
    "abs_zscore_all=outdict[\"abs_zscore_all\"] # this file is too large to push to git, please generate it locally by running step 1 in single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append abs_zscore from 24 subject together\n",
    "abs_zscore_subj_L_append =  [[] for i in range(12)]\n",
    "for ses in range(12):\n",
    "    for trl in range(12):\n",
    "        abs_zscore_subj_L_append[ses].append(abs_zscore_all[ses][trl][0]) \n",
    "\n",
    "abs_zscore_subj_R_append =  [[] for i in range(12)]\n",
    "for ses in range(12):\n",
    "    for trl in range(12):\n",
    "        abs_zscore_subj_R_append[ses].append(abs_zscore_all[ses][trl][1]) \n",
    "\n",
    "abs_zscore_subj_append=[abs_zscore_subj_L_append, abs_zscore_subj_R_append]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ampdata_subj_L =  [[] for i in range(12)]\n",
    "ampdata_subj_R =  [[] for i in range(12)]\n",
    "ampdata_subj   =  [ampdata_subj_L, ampdata_subj_R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the trials in each subject\n",
    "for subj in range(2):\n",
    "    for ses in range(12):\n",
    "        ampdata_subj[subj][ses]=np.concatenate(abs_zscore_subj_append[subj][ses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partialcorrelation(ampdata,ncv=5):\n",
    "    pc_lasso = GraphicalLassoCV(cv=ncv)\n",
    "    nbin = np.shape(ampdata)[1]\n",
    "    nchan = np.shape(ampdata)[2]\n",
    "    pcorr = np.zeros((nbin,nchan,nchan))\n",
    "    alphas = np.zeros(nbin)\n",
    "    # likelihoods = list()\n",
    "    likelihoods = np.zeros(nbin)\n",
    "    covmat = np.zeros((nbin,nchan,nchan))\n",
    "    for f in range(nbin):\n",
    "        xx= np.abs(np.squeeze(ampdata[:,f,:]))\n",
    "        pc_lasso.fit(xx) # the system is too ill for this solver\n",
    "        covariance = pc_lasso.covariance_\n",
    "        precision = pc_lasso.precision_\n",
    "        alphas[f] = pc_lasso.alpha_\n",
    "        dict_cvresults=pc_lasso.cv_results_\n",
    "        best_alpha_ind=np.where(dict_cvresults['alphas']==pc_lasso.alpha_)\n",
    "        # likelihoods.append(pc_lasso.cv_results_[\"mean_test_score\"])\n",
    "        likelihoods[f] = pc_lasso.cv_results_[\"mean_test_score\"][best_alpha_ind][0]\n",
    "        parcor = np.zeros((32,32))\n",
    "        y = np.diag(precision)\n",
    "        yy = np.outer(y,y)\n",
    "        yy = np.sqrt(yy)\n",
    "        parcor = precision/yy\n",
    "        pcorr[f,:,:] = parcor\n",
    "        y = np.diag(covariance)\n",
    "        yy = np.outer(y,y)\n",
    "        yy = np.sqrt(yy)\n",
    "        parcor_cov = covariance/yy        \n",
    "        covmat[f,:,:] = parcor_cov \n",
    "    return pcorr,covmat,alphas,likelihoods  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "epoch = 1 #units: seconds\n",
    "maxf = 30 #units: Hz\n",
    "maxbin = maxf*epoch #convert maxf into number of bins to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit lasso model for all subjects\n",
    "pcorr=np.zeros((2,12,maxbin,32,32))\n",
    "covmat=np.zeros((2,12,maxbin,32,32))\n",
    "alphas=np.zeros((2,12,maxbin))\n",
    "likelihoods=np.zeros((2,12,maxbin))\n",
    "for subj in range(2):\n",
    "    for ses in range(12):\n",
    "        ampdata_subj\n",
    "        pcorr[subj][ses],covmat[subj][ses],alphas[subj][ses],likelihoods[subj][ses] = \\\n",
    "            partialcorrelation(ampdata_subj[subj][ses],ncv=5)\n",
    "\n",
    "outdict = dict()\n",
    "outdict['pcorr'] = pcorr\n",
    "outdict['covmat']= covmat \n",
    "outdict['alpha'] = alphas\n",
    "outdict['likelihood'] = likelihoods\n",
    "\n",
    "# take 0.5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save syn_pcorr\n",
    "savemat('pcorr_subj',outdict,store_python_metadata=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92151dfd069a0a59e8342616fc1173887a1e4fb36078a0282eb66543f78e24f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
