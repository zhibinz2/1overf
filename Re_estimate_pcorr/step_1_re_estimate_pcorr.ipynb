{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from hdf5storage import loadmat,savemat\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence_test(fval, previous_fval, threshold=1e-4, warn=False):\n",
    "    \"\"\"\n",
    "    Check if an objective function has converged.\n",
    "\n",
    "    We have converged if the slope of the function falls below 'threshold',\n",
    "    i.e., |f(t) - f(t-1)| / avg < threshold,\n",
    "    where avg = (|f(t)| + |f(t-1)|)/2.\n",
    "    'threshold' defaults to 1e-4.\n",
    "    This stopping criterion is from Numerical Recipes in C p423.\n",
    "    \"\"\"\n",
    "\n",
    "    converged = False\n",
    "    delta_fval = np.abs(fval - previous_fval)\n",
    "    avg_fval = (np.abs(fval) + np.abs(previous_fval) + np.finfo(float).eps) / 2\n",
    "\n",
    "    if delta_fval / avg_fval < threshold:\n",
    "        converged = True\n",
    "\n",
    "    if warn and (fval - previous_fval) < -2 * np.finfo(float).eps:  # fval < previous_fval\n",
    "        warnings.warn('objective decreased!', UserWarning)\n",
    "\n",
    "    return converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ggmFitHtf(S, G, maxIter=30):\n",
    "    # MLE for a precision matrix given known zeros in the graph\n",
    "    # S is d*d sample covariance matrix\n",
    "    # G is d*d adjacency matrix\n",
    "    # We use the algorithm due to \n",
    "    # Hastie, Tibshirani & Friedman (\"Elements\" book, 2nd Ed, 2008, p633)\n",
    "    # This file is from pmtk3.googlecode.com\n",
    "    p = S.shape[0] \n",
    "    W = S # W = inv(precMat)\n",
    "    precMat = np.zeros((p, p))\n",
    "    beta = np.zeros(p-1)\n",
    "    iter = 1\n",
    "    converged = False\n",
    "    normW = np.linalg.norm(W)\n",
    "    while not converged:\n",
    "        for i in range(p):\n",
    "            # partition W & S for i\n",
    "            noti = np.concatenate((np.arange(i), np.arange(i+1, p)))\n",
    "            W11 = W[noti,:][:,noti]\n",
    "            w12 = W[noti,i]\n",
    "            s22 = S[i,i]\n",
    "            s12 = S[noti,i]\n",
    "\n",
    "            # find G's non-zero index in W11\n",
    "            idx = np.nonzero(G[noti,i])[0]  # non-zeros in G11\n",
    "            beta[:] = 0\n",
    "            beta[idx] = np.linalg.solve(W11[np.ix_(idx,idx)], s12[idx])\n",
    "\n",
    "            # update W\n",
    "            w12 = W11 @ beta\n",
    "            W[noti,i] = w12 \n",
    "            W[i,noti] = w12\n",
    "\n",
    "            # update precMat (technically only needed on last iteration)\n",
    "            p22 = max([0,  1/(s22 - w12 @ beta)])  # must be non-neg\n",
    "            p12 = -beta * p22\n",
    "            precMat[noti,i] = p12\n",
    "            precMat[i,noti] = p12\n",
    "            precMat[i,i] = p22\n",
    "\n",
    "        converged = convergence_test(np.linalg.norm(W),normW) | (iter > maxIter)\n",
    "        normW = np.linalg.norm(W)\n",
    "        iter += 1\n",
    "\n",
    "    # ensure symmetry \n",
    "    precMat = (precMat + precMat.T)/2\n",
    "    \n",
    "    return precMat, iter\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re-estimate the 12 session x 2 subjects x 12 trial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General: a single model for all\n",
    "data = loadmat('/home/zhibinz2/Documents/GitHub/1overf/Pcorr_single_model/pcorr_single.mat')\n",
    "singlepcorr = data['pcorr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize file in time sequence\n",
    "filedates=[20220713,20220721,20220804,20220808,20220810,20220811,20220815,20220816,20221003,2022100401,2022100402,20221005]\n",
    "numSes=len(filedates)\n",
    "# file directory of the pcorr output for each session\n",
    "filedir=\"/home/zhibinz2/Documents/GitHub/1overf/Python_codes/\" # your own data directory\n",
    "pathname = 'pcorr/'\n",
    "dir=filedir+pathname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_parcor_all=np.zeros([12,12,2,30,32,32])\n",
    "iter_all=np.zeros([12,12,2,30,32,32])\n",
    "\n",
    "for ses in range(12):\n",
    "\tfilename='clean_'+str(filedates[ses])+'_pcorr.mat'\n",
    "\tspectral=loadmat(dir+filename)\n",
    "\tampcorr = spectral['empirical_amplitude_correlation']\n",
    "\tfor trl in range(12):\n",
    "\t\tfor subj in range(2):\n",
    "\t\t\tfor freq in range(30):\n",
    "\t\t\t\t# single trial\n",
    "\t\t\t\tS = ampcorr[subj,trl,freq,:,:]\n",
    "\t\t\t\t# general model\n",
    "\t\t\t\tx = singlepcorr[freq,:,:]\n",
    "\t\t\t\tG = x.astype('bool')\n",
    "\t\t\t\tG = G.astype('int')\n",
    "\t\t\t\t# re-estimate\n",
    "\t\t\t\tprecMat,iter = ggmFitHtf(S, G, maxIter=100)\n",
    "\t\t\t\ty = np.diag(precMat)\n",
    "\t\t\t\tyy = np.outer(y,y)\n",
    "\t\t\t\tyy = np.sqrt(yy)\n",
    "\t\t\t\tparcor = precMat/yy \n",
    "\t\t\t\tre_parcor_all[ses,trl,subj,freq,:,:]=parcor\n",
    "\t\t\t\titer_all[ses,trl,subj,freq,:,:]=iter\n",
    "\n",
    "# takes 1 min\t\n",
    "\t\t\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "outdict=dict()\n",
    "outdict['re_parcor_all']=re_parcor_all\n",
    "outdict['iter_all']=iter_all\n",
    "savemat('re_estimate',outdict,store_python_metadata=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "organize into 2 syn types 4 conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load \n",
    "# outdict=loadmat('re_estimate.mat')\n",
    "# re_parcor_all=outdict[\"re_parcor_all\"]\n",
    "# iter_all=outdict[\"iter_all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load condition_all\n",
    "outdict=loadmat('/home/zhibinz2/Documents/GitHub/1overf/Python_codes/conditions_all.mat')\n",
    "conditions_all=outdict[\"conditions_all\"]\n",
    "\n",
    "# Organize indicies \n",
    "Uncoupled_Ind=np.zeros((12,3))\n",
    "L_Lead_Ind=np.zeros((12,3)) # they were leading indicies for L subject but following for R\n",
    "R_Lead_Ind=np.zeros((12,3))\n",
    "Mutual_Ind=np.zeros((12,3))\n",
    "\n",
    "for ses in range(12):\n",
    "    Uncoupled_Ind[ses]=np.asarray(np.where(conditions_all[ses]==1))\n",
    "    L_Lead_Ind[ses]=np.asarray(np.where(conditions_all[ses]==2))\n",
    "    R_Lead_Ind[ses]=np.asarray(np.where(conditions_all[ses]==3))\n",
    "    Mutual_Ind[ses]=np.asarray(np.where(conditions_all[ses]==4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  abs_zscore into 4 conditions in 2 syn types\n",
    "# append all trials of the same condition together\n",
    "synch_Uncoupled = [[] for i in range(30)]\n",
    "synch_Leading   = [[] for i in range(30)]\n",
    "synch_Following = [[] for i in range(30)]\n",
    "synch_Mutual    = [[] for i in range(30)]\n",
    "\n",
    "synco_Uncoupled = [[] for i in range(30)]\n",
    "synco_Leading   = [[] for i in range(30)]\n",
    "synco_Following = [[] for i in range(30)]\n",
    "synco_Mutual    = [[] for i in range(30)]\n",
    "\n",
    "\n",
    "for ses in list(range(0,12,2)): # synch [0, 2, 4, 6, 8, 10]\n",
    "    for subj in range(2):\n",
    "        for trl in range(3):\n",
    "            for freq in range(30):\n",
    "                if subj == 0:\n",
    "                    synch_Uncoupled[freq].append(re_parcor_all[ses,int(Uncoupled_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synch_Leading[freq].append(re_parcor_all[ses,int(L_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synch_Following[freq].append(re_parcor_all[ses,int(R_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synch_Mutual[freq].append(re_parcor_all[ses,int(Mutual_Ind[ses][trl]),subj,freq,:,:])\n",
    "                else:\n",
    "                    synch_Uncoupled[freq].append(re_parcor_all[ses,int(Uncoupled_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synch_Leading[freq].append(re_parcor_all[ses,int(R_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synch_Following[freq].append(re_parcor_all[ses,int(L_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synch_Mutual[freq].append(re_parcor_all[ses,int(Mutual_Ind[ses][trl]),subj,freq,:,:])\n",
    "\n",
    "for ses in list(range(1,12,2)): # [1, 3, 5, 7, 9, 11]\n",
    "    for subj in range(2):\n",
    "        for trl in range(3):\n",
    "            for freq in range(30):\n",
    "                if subj == 0:\n",
    "                    synco_Uncoupled[freq].append(re_parcor_all[ses,int(Uncoupled_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synco_Leading[freq].append(re_parcor_all[ses,int(L_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synco_Following[freq].append(re_parcor_all[ses,int(R_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synco_Mutual[freq].append(re_parcor_all[ses,int(Mutual_Ind[ses][trl]),subj,freq,:,:])\n",
    "                else:\n",
    "                    synco_Uncoupled[freq].append(re_parcor_all[ses,int(Uncoupled_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synco_Leading[freq].append(re_parcor_all[ses,int(R_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synco_Following[freq].append(re_parcor_all[ses,int(L_Lead_Ind[ses][trl]),subj,freq,:,:])\n",
    "                    synco_Mutual[freq].append(re_parcor_all[ses,int(Mutual_Ind[ses][trl]),subj,freq,:,:])\n",
    "\n",
    "# appended 36 trials in each frequencies for each conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sum the re_parcor matricies in each frequency\n",
    "# sum_synch_Uncoupled = np.zeros((30,32,32))\n",
    "# sum_synch_Leading   = np.zeros((30,32,32))\n",
    "# sum_synch_Following = np.zeros((30,32,32))\n",
    "# sum_synch_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "# sum_synco_Uncoupled = np.zeros((30,32,32))\n",
    "# sum_synco_Leading   = np.zeros((30,32,32))\n",
    "# sum_synco_Following = np.zeros((30,32,32))\n",
    "# sum_synco_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "# for freq in range(30):\n",
    "#     sum_synch_Uncoupled[freq] = sum(synch_Uncoupled[freq])\n",
    "#     sum_synch_Leading[freq]   = sum(synch_Leading[freq])\n",
    "#     sum_synch_Following[freq] = sum(synch_Following[freq])\n",
    "#     sum_synch_Mutual[freq]    = sum(synch_Mutual[freq])\n",
    "\n",
    "#     sum_synco_Uncoupled[freq] = sum(synco_Uncoupled[freq])\n",
    "#     sum_synco_Leading[freq]   = sum(synco_Leading[freq])\n",
    "#     sum_synco_Following[freq] = sum(synco_Following[freq])\n",
    "#     sum_synco_Mutual[freq]    = sum(synco_Mutual[freq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # averaging the sum of the re_parcor matricies in each frequency by 36 trial\n",
    "# mean_synch_Uncoupled = np.zeros((30,32,32))\n",
    "# mean_synch_Leading   = np.zeros((30,32,32))\n",
    "# mean_synch_Following = np.zeros((30,32,32))\n",
    "# mean_synch_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "# mean_synco_Uncoupled = np.zeros((30,32,32))\n",
    "# mean_synco_Leading   = np.zeros((30,32,32))\n",
    "# mean_synco_Following = np.zeros((30,32,32))\n",
    "# mean_synco_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "# for freq in range(30):\n",
    "#     mean_synch_Uncoupled [freq]= sum_synch_Uncoupled[freq] /36\n",
    "#     mean_synch_Leading   [freq]= sum_synch_Leading[freq]   /36\n",
    "#     mean_synch_Following [freq]= sum_synch_Following[freq] /36\n",
    "#     mean_synch_Mutual    [freq]= sum_synch_Mutual[freq]    /36\n",
    "\n",
    "#     mean_synco_Uncoupled [freq]= sum_synco_Uncoupled[freq] /36\n",
    "#     mean_synco_Leading   [freq]= sum_synco_Leading[freq]   /36\n",
    "#     mean_synco_Following [freq]= sum_synco_Following[freq] /36\n",
    "#     mean_synco_Mutual    [freq]= sum_synco_Mutual[freq]    /36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of the re_parcor matricies in each frequency\n",
    "mean_synch_Uncoupled = np.zeros((30,32,32))\n",
    "mean_synch_Leading   = np.zeros((30,32,32))\n",
    "mean_synch_Following = np.zeros((30,32,32))\n",
    "mean_synch_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "mean_synco_Uncoupled = np.zeros((30,32,32))\n",
    "mean_synco_Leading   = np.zeros((30,32,32))\n",
    "mean_synco_Following = np.zeros((30,32,32))\n",
    "mean_synco_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "for freq in range(30):\n",
    "    mean_synch_Uncoupled[freq] = (np.asarray(synch_Uncoupled[freq])).mean(0)\n",
    "    mean_synch_Leading[freq]   = (np.asarray(synch_Leading  [freq])).mean(0)\n",
    "    mean_synch_Following[freq] = (np.asarray(synch_Following[freq])).mean(0)\n",
    "    mean_synch_Mutual[freq]    = (np.asarray(synch_Mutual   [freq])).mean(0)\n",
    "\n",
    "    mean_synco_Uncoupled[freq] = (np.asarray(synco_Uncoupled[freq])).mean(0)\n",
    "    mean_synco_Leading[freq]   = (np.asarray(synco_Leading  [freq])).mean(0)\n",
    "    mean_synco_Following[freq] = (np.asarray(synco_Following[freq])).mean(0)\n",
    "    mean_synco_Mutual[freq]    = (np.asarray(synco_Mutual   [freq])).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std of the re_parcor matricies in each frequency\n",
    "std_synch_Uncoupled = np.zeros((30,32,32))\n",
    "std_synch_Leading   = np.zeros((30,32,32))\n",
    "std_synch_Following = np.zeros((30,32,32))\n",
    "std_synch_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "std_synco_Uncoupled = np.zeros((30,32,32))\n",
    "std_synco_Leading   = np.zeros((30,32,32))\n",
    "std_synco_Following = np.zeros((30,32,32))\n",
    "std_synco_Mutual    = np.zeros((30,32,32))\n",
    "\n",
    "for freq in range(30):\n",
    "    std_synch_Uncoupled[freq] = (np.asarray(synch_Uncoupled[freq])).std(0)\n",
    "    std_synch_Leading[freq]   = (np.asarray(synch_Leading  [freq])).std(0)\n",
    "    std_synch_Following[freq] = (np.asarray(synch_Following[freq])).std(0)\n",
    "    std_synch_Mutual[freq]    = (np.asarray(synch_Mutual   [freq])).std(0)\n",
    "\n",
    "    std_synco_Uncoupled[freq] = (np.asarray(synco_Uncoupled[freq])).std(0)\n",
    "    std_synco_Leading[freq]   = (np.asarray(synco_Leading  [freq])).std(0)\n",
    "    std_synco_Following[freq] = (np.asarray(synco_Following[freq])).std(0)\n",
    "    std_synco_Mutual[freq]    = (np.asarray(synco_Mutual   [freq])).std(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_synch_4condi=[mean_synch_Uncoupled,mean_synch_Leading,mean_synch_Following,mean_synch_Mutual]\n",
    "mean_synco_4condi=[mean_synco_Uncoupled, mean_synco_Leading, mean_synco_Following, mean_synco_Mutual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of parcor selection\n",
    "figure,axs = plt.subplots(30,4,constrained_layout=True)\n",
    "for condi in range(4):\n",
    "\tfor freq in range(30):\n",
    "\t\tplt.sca(axs[freq,condi])\n",
    "\t\tplt.plot().imshow(sum_4states[state][freq,:,:],\\\n",
    "\t\t\t\t\tvmin=0,vmax=72,cmap='viridis')#RdBu_r viridis\n",
    "\t\taxs[freq,state].set_title(states4names[state]+' freq: '+str(freq+1)+' Hz')\n",
    "\t\tfigure.colorbar(im, ax=axs[freq,state])\n",
    "figure.suptitle('sum of squared of partial_correlation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "92151dfd069a0a59e8342616fc1173887a1e4fb36078a0282eb66543f78e24f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
